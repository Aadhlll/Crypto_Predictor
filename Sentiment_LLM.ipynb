{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjx3p74KJaif"
      },
      "source": [
        "### Working Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXgwC-g7JgZv"
      },
      "source": [
        "### Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "c18aqSR-Jk99",
        "outputId": "410fec33-51ac-4285-9907-2341ffb4a292"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UAE Pro League Teams Up With Chiliz to Bring W...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Polkadot Price Forecast: Will DOT Reach the $5...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Binance Opts for USDC Reserves While It Seeks ...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Worldcoin Introduces World Chain Layer-2 Amids...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BlackRock Was Tipped Off About High Inflation,...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Is the Bitcoin, Crypto Bull Market Over? Analy...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ripple (XRP) Price Analysis: 13% Recovery or 1...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This Is How Nearly 1 Billion Polygon (MATIC) W...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Shiba Inu (SHIB) Price Forecast: Potential Bul...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Will Pepe (PEPE) Price Mark a New All-Time Hig...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline       Date\n",
              "0  UAE Pro League Teams Up With Chiliz to Bring W...  18-Apr-24\n",
              "1  Polkadot Price Forecast: Will DOT Reach the $5...  18-Apr-24\n",
              "2  Binance Opts for USDC Reserves While It Seeks ...  18-Apr-24\n",
              "3  Worldcoin Introduces World Chain Layer-2 Amids...  18-Apr-24\n",
              "4  BlackRock Was Tipped Off About High Inflation,...  18-Apr-24\n",
              "5  Is the Bitcoin, Crypto Bull Market Over? Analy...  18-Apr-24\n",
              "6  Ripple (XRP) Price Analysis: 13% Recovery or 1...  17-Apr-24\n",
              "7  This Is How Nearly 1 Billion Polygon (MATIC) W...  17-Apr-24\n",
              "8  Shiba Inu (SHIB) Price Forecast: Potential Bul...  17-Apr-24\n",
              "9  Will Pepe (PEPE) Price Mark a New All-Time Hig...  17-Apr-24"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(r'D:\\DATA SCIENCE\\Internship\\CrypoDataAnalysis\\combined.csv')\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDa4P51mhuIa",
        "outputId": "e1e5191c-f688-4793-a05e-38b0a4343e9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27056, 2)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQJMBnOcDZNn"
      },
      "source": [
        "### Setting up Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iyuK0Kl_4TGs"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "q4aOPMsiPZYx",
        "outputId": "9b2f8498-b1df-4554-f7eb-09ca45089536"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UAE Pro League Teams Up With Chiliz to Bring W...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Polkadot Price Forecast: Will DOT Reach the $5...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Binance Opts for USDC Reserves While It Seeks ...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Worldcoin Introduces World Chain Layer-2 Amids...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BlackRock Was Tipped Off About High Inflation,...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Is the Bitcoin, Crypto Bull Market Over? Analy...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ripple (XRP) Price Analysis: 13% Recovery or 1...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This Is How Nearly 1 Billion Polygon (MATIC) W...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Shiba Inu (SHIB) Price Forecast: Potential Bul...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Will Pepe (PEPE) Price Mark a New All-Time Hig...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline       Date\n",
              "0  UAE Pro League Teams Up With Chiliz to Bring W...  18-Apr-24\n",
              "1  Polkadot Price Forecast: Will DOT Reach the $5...  18-Apr-24\n",
              "2  Binance Opts for USDC Reserves While It Seeks ...  18-Apr-24\n",
              "3  Worldcoin Introduces World Chain Layer-2 Amids...  18-Apr-24\n",
              "4  BlackRock Was Tipped Off About High Inflation,...  18-Apr-24\n",
              "5  Is the Bitcoin, Crypto Bull Market Over? Analy...  18-Apr-24\n",
              "6  Ripple (XRP) Price Analysis: 13% Recovery or 1...  17-Apr-24\n",
              "7  This Is How Nearly 1 Billion Polygon (MATIC) W...  17-Apr-24\n",
              "8  Shiba Inu (SHIB) Price Forecast: Potential Bul...  17-Apr-24\n",
              "9  Will Pepe (PEPE) Price Mark a New All-Time Hig...  17-Apr-24"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_sample = data[0:10]\n",
        "\n",
        "#test_set_sample['pred_label'] = ''\n",
        "#test_set_sample.set_index('Date',inplace=True)\n",
        "test_set_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKXFgiCSTvae",
        "outputId": "3de94f14-8490-4d02-cd8a-ae8d92a40edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   index                                           Headline       Date\n",
            "0      1  UAE Pro League Teams Up With Chiliz to Bring W...  18-Apr-24\n",
            "1      2  Polkadot Price Forecast: Will DOT Reach the $5...  18-Apr-24\n",
            "2      3  Binance Opts for USDC Reserves While It Seeks ...  18-Apr-24\n",
            "3      4  Worldcoin Introduces World Chain Layer-2 Amids...  18-Apr-24\n",
            "4      5  BlackRock Was Tipped Off About High Inflation,...  18-Apr-24\n",
            "5      6  Is the Bitcoin, Crypto Bull Market Over? Analy...  18-Apr-24\n",
            "6      7  Ripple (XRP) Price Analysis: 13% Recovery or 1...  17-Apr-24\n",
            "7      8  This Is How Nearly 1 Billion Polygon (MATIC) W...  17-Apr-24\n",
            "8      9  Shiba Inu (SHIB) Price Forecast: Potential Bul...  17-Apr-24\n",
            "9     10  Will Pepe (PEPE) Price Mark a New All-Time Hig...  17-Apr-24\n"
          ]
        }
      ],
      "source": [
        "# Create an index column starting from 1\n",
        "test_set_sample.insert(0, 'index', range(1, len(test_set_sample) + 1))\n",
        "\n",
        "print(test_set_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FSWnncxN4E1d"
      },
      "outputs": [],
      "source": [
        "dct = test_set_sample[['index','Headline']].to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiAV6wHt4QhK",
        "outputId": "9991f1bc-79d4-40ed-af87-1ebd50f17e55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'index': 10,\n",
              " 'Headline': 'Will Pepe (PEPE) Price Mark a New All-Time High by the End of April?'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dct[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ6XuTed6f9Z",
        "outputId": "d0376cd1-cceb-4929-86f9-e2a48f26c2fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\"index\": 1, \"Headline\": \"UAE Pro League Teams Up With Chiliz to Bring Web3 for Fans\"}, {\"index\": 2, \"Headline\": \"Polkadot Price Forecast: Will DOT Reach the $5 Level Soon?\"}, {\"index\": 3, \"Headline\": \"Binance Opts for USDC Reserves While It Seeks India Return and Dubai Entry\"}, {\"index\": 4, \"Headline\": \"Worldcoin Introduces World Chain Layer-2 Amidst Regulatory Spotlight\"}, {\"index\": 5, \"Headline\": \"BlackRock Was Tipped Off About High Inflation, Uses Bitcoin to Hedge\"}, {\"index\": 6, \"Headline\": \"Is the Bitcoin, Crypto Bull Market Over? Analysts Weigh In\"}, {\"index\": 7, \"Headline\": \"Ripple (XRP) Price Analysis: 13% Recovery or 13% Decline \\u2013 What Comes Next?\"}, {\"index\": 8, \"Headline\": \"This Is How Nearly 1 Billion Polygon (MATIC) Will Witness Profits\"}, {\"index\": 9, \"Headline\": \"Shiba Inu (SHIB) Price Forecast: Potential Bullish Bounce at Golden Ratio?\"}, {\"index\": 10, \"Headline\": \"Will Pepe (PEPE) Price Mark a New All-Time High by the End of April?\"}]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# Convert dictionary to JSON string\n",
        "json_string = json.dumps(dct)\n",
        "\n",
        "print(json_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qlgtqnlR7Y6W",
        "outputId": "66d6b39f-4378-4140-edc8-814c56fec147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'index\": 9, \"Headline\": \"Shiba Inu (SHIB) Price Forecast: Potential Bullish Bounce at Golden Ratio?\"}, {\"index\": 10, \"Headline\": \"Will Pepe (PEPE) Price Mark a New All-Time High by the End of April?\"}'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json_string[-200:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "ZoGCR2G-PKzX",
        "outputId": "ff61a5d7-7ef9-4daa-fb40-9a46f6ee3824"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Nahala\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[{\"index\": 1, \"pred_score\": 0.3}, {\"index\": 2, \"pred_score\": 0.1}, {\"index\": 3, \"pred_score\": 0.2}, {\"index\": 4, \"pred_score\": 0.0}, {\"index\": 5, \"pred_score\": 0.4}, {\"index\": 6, \"pred_score\": -0.1}, {\"index\": 7, \"pred_score\": 0.0}, {\"index\": 8, \"pred_score\": 0.7}, {\"index\": 9, \"pred_score\": 0.3}, {\"index\": 10, \"pred_score\": 0.1}]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyA9-COrUP5zX1frzRAxls1lhJJ8Cw7F1AQ\")\n",
        "\n",
        "# Create the model\n",
        "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
        "generation_config = {\n",
        "  \"temperature\": 0,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\":100000 ,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-pro-latest\",\n",
        "  safety_settings=safety_settings,\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"You are an advanced sentiment analysis model designed to evaluate the sentiment of news headlines related to cryptocurrency. Your task is to categorize each headline into one of three categories: positive, negative, or neutral. \\n A positive sentiment indicates that the headline is likely to have a beneficial impact on the perception of the cryptocurrency market, suggesting optimism or good news.\\nA negative sentiment indicates that the headline is likely to have an adverse impact on the perception of the cryptocurrency market, suggesting pessimism or bad news.\\nA neutral sentiment indicates that the headline does not express a clear positive or negative sentiment, or it has no significant impact on the perception of the cryptocurrency market.\\nFor each headline, provide a sentiment score ranging from -1 to 1, where:\\n- A score close to 1 indicates a strong positive sentiment,\\n- A score close to -1 indicates a strong negative sentiment,\\n- A score close to 0 indicates a neutral sentiment.\\n\\nHere are some examples for clarity:\\n1. Headline: \\\"Bitcoin prices soar to new all-time high.\\\"\\n   Sentiment: Positive\\n   Score: 0.9\\n2. Headline: \\\"Cryptocurrency market faces regulatory crackdowns.\\\"\\n   Sentiment: Negative\\n   Score: -0.8\\n3. Headline: \\\"Blockchain technology adoption continues to grow steadily.\\\"\\n   Sentiment: Neutral\\n   Score: 0.1\\nYour task is to update predicted score under 'pred_label' in the json provided. Don't make any changes to the Output format..\\nPlease analyze the following headlines and provide the sentiment and score for each:\\nNote: The analysis should be consistent across repeated evaluations of the same headlines.Note: Output should only have Index and corresponding pred_score \",)\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\":\n",
        "        json_string\n",
        "      ,\n",
        "    },\n",
        "\n",
        "  ]\n",
        ")\n",
        "\n",
        "response = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "\n",
        "print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "PJH-KkWqPLDI",
        "outputId": "a660bc46-fb22-49fb-8983-06e1c48c2b1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Date</th>\n",
              "      <th>pred_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>UAE Pro League Teams Up With Chiliz to Bring W...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Polkadot Price Forecast: Will DOT Reach the $5...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Binance Opts for USDC Reserves While It Seeks ...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Worldcoin Introduces World Chain Layer-2 Amids...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>BlackRock Was Tipped Off About High Inflation,...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Is the Bitcoin, Crypto Bull Market Over? Analy...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Ripple (XRP) Price Analysis: 13% Recovery or 1...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>This Is How Nearly 1 Billion Polygon (MATIC) W...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Shiba Inu (SHIB) Price Forecast: Potential Bul...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Will Pepe (PEPE) Price Mark a New All-Time Hig...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                           Headline       Date  \\\n",
              "0      1  UAE Pro League Teams Up With Chiliz to Bring W...  18-Apr-24   \n",
              "1      2  Polkadot Price Forecast: Will DOT Reach the $5...  18-Apr-24   \n",
              "2      3  Binance Opts for USDC Reserves While It Seeks ...  18-Apr-24   \n",
              "3      4  Worldcoin Introduces World Chain Layer-2 Amids...  18-Apr-24   \n",
              "4      5  BlackRock Was Tipped Off About High Inflation,...  18-Apr-24   \n",
              "5      6  Is the Bitcoin, Crypto Bull Market Over? Analy...  18-Apr-24   \n",
              "6      7  Ripple (XRP) Price Analysis: 13% Recovery or 1...  17-Apr-24   \n",
              "7      8  This Is How Nearly 1 Billion Polygon (MATIC) W...  17-Apr-24   \n",
              "8      9  Shiba Inu (SHIB) Price Forecast: Potential Bul...  17-Apr-24   \n",
              "9     10  Will Pepe (PEPE) Price Mark a New All-Time Hig...  17-Apr-24   \n",
              "\n",
              "   pred_score  \n",
              "0         0.3  \n",
              "1         0.1  \n",
              "2         0.2  \n",
              "3         0.0  \n",
              "4         0.4  \n",
              "5        -0.1  \n",
              "6         0.0  \n",
              "7         0.7  \n",
              "8         0.3  \n",
              "9         0.1  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Clean the data by stripping the backticks\n",
        "json_data = response.text.strip(\"`json\")\n",
        "\n",
        "# Load the cleaned data and convert to DataFrame\n",
        "jsontolist = json.loads(json_data)\n",
        "df_sample = pd.DataFrame(jsontolist)\n",
        "merged_data = pd.merge(test_set_sample, df_sample, on='index')\n",
        "merged_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og-xNZulUe2H"
      },
      "source": [
        "#Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lALKX2QUsIw",
        "outputId": "68976b7a-bea5-4b27-eaab-68b2f7f67cd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       index                                           Headline       Date\n",
            "0          1  UAE Pro League Teams Up With Chiliz to Bring W...  18-Apr-24\n",
            "1          2  Polkadot Price Forecast: Will DOT Reach the $5...  18-Apr-24\n",
            "2          3  Binance Opts for USDC Reserves While It Seeks ...  18-Apr-24\n",
            "3          4  Worldcoin Introduces World Chain Layer-2 Amids...  18-Apr-24\n",
            "4          5  BlackRock Was Tipped Off About High Inflation,...  18-Apr-24\n",
            "...      ...                                                ...        ...\n",
            "27051  27052  Gold, Stocks, and Bitcoin: Weekly Overview — J...  01-Jul-21\n",
            "27052  27053  Calaxy Raises $7.5M in Funding to Develop Fan App  01-Jul-21\n",
            "27053  27054       BTCD Gets Rejected at 48% – Will Alts Rally?  01-Jul-21\n",
            "27054  27055         WazirX Hires TRM Labs to Help Detect Fraud  01-Jul-21\n",
            "27055  27056  BTC On-Chain Analysis: CDD Falls to New Yearly...  01-Jul-21\n",
            "\n",
            "[27056 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Create an index column starting from 1\n",
        "data.insert(0, 'index', range(1, len(data) + 1))\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Q90bn3YbxGBI",
        "outputId": "abef080c-cdad-46e2-de08-0be8ebe60091"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import json\\nimport pandas as pd\\nimport time\\n\\n\\nBatch_size = 50\\nfull_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\\n\\nfor i in range(0, len(data), Batch_size):\\n    batch = data[i:i+Batch_size]\\n    dct1 = batch[[\\'index\\',\\'Headline\\']].to_dict(orient=\\'records\\')\\n    json_string1 = json.dumps(dct1)\\n\\n    chat_session = model.start_chat(\\n        history=[\\n            {\\n                \"role\": \"user\",\\n                \"parts\": [\\n                    json_string1\\n                ],\\n            },\\n        ]\\n    )\\n\\n    response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\\n    print(\"Sleeping\")\\n    time.sleep(10)  # Wait for 30 second between requests\\n    print(\"Woke UP\")\\n    # Clean the data by stripping the backticks and any unwanted characters\\n    json_data1 = response1.text.strip(\"`\").strip(\"json\")\\n\\n    # Load the cleaned data and convert to DataFrame\\n    jsontolist1 = json.loads(json_data1)\\n    df_sample1 = pd.DataFrame(jsontolist1)\\n\\n    # Merge the dataframes\\n    merged_data1 = pd.merge(data, df_sample1, on=\\'index\\')\\n\\n    # Update the full merged data DataFrame\\n    full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\\n\\n    # Save the full merged data to CSV\\n    # Save the full merged data to CSV in the specified folder\\n    full_merged_data1.to_csv(f\\'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv\\', index=False)\\n    print(f\"Batch {i} completed.\")'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import json\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "Batch_size = 50\n",
        "full_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\n",
        "\n",
        "for i in range(0, len(data), Batch_size):\n",
        "    batch = data[i:i+Batch_size]\n",
        "    dct1 = batch[['index','Headline']].to_dict(orient='records')\n",
        "    json_string1 = json.dumps(dct1)\n",
        "\n",
        "    chat_session = model.start_chat(\n",
        "        history=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    json_string1\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "    print(\"Sleeping\")\n",
        "    time.sleep(10)  # Wait for 30 second between requests\n",
        "    print(\"Woke UP\")\n",
        "    # Clean the data by stripping the backticks and any unwanted characters\n",
        "    json_data1 = response1.text.strip(\"`\").strip(\"json\")\n",
        "\n",
        "    # Load the cleaned data and convert to DataFrame\n",
        "    jsontolist1 = json.loads(json_data1)\n",
        "    df_sample1 = pd.DataFrame(jsontolist1)\n",
        "\n",
        "    # Merge the dataframes\n",
        "    merged_data1 = pd.merge(data, df_sample1, on='index')\n",
        "\n",
        "    # Update the full merged data DataFrame\n",
        "    full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\n",
        "\n",
        "    # Save the full merged data to CSV\n",
        "    # Save the full merged data to CSV in the specified folder\n",
        "    full_merged_data1.to_csv(f'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv', index=False)\n",
        "    print(f\"Batch {i} completed.\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import json\\nimport pandas as pd\\nimport time\\n\\n\\nBatch_size = 50\\nfull_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\\n\\nfor i in range(3450, len(data), Batch_size):\\n    batch = data[i:i+Batch_size]\\n    dct1 = batch[[\\'index\\',\\'Headline\\']].to_dict(orient=\\'records\\')\\n    json_string1 = json.dumps(dct1)\\n\\n    chat_session = model.start_chat(\\n        history=[\\n            {\\n                \"role\": \"user\",\\n                \"parts\": [\\n                    json_string1\\n                ],\\n            },\\n        ]\\n    )\\n\\n    response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\\n    print(\"Sleeping\")\\n    time.sleep(10)  # Wait for 30 second between requests\\n    print(\"Woke UP\")\\n    # Clean the data by stripping the backticks and any unwanted characters\\n    json_data1 = response1.text.strip(\"`\").strip(\"json\")\\n\\n    # Load the cleaned data and convert to DataFrame\\n    jsontolist1 = json.loads(json_data1)\\n    df_sample1 = pd.DataFrame(jsontolist1)\\n\\n    # Merge the dataframes\\n    merged_data1 = pd.merge(data, df_sample1, on=\\'index\\')\\n\\n    # Update the full merged data DataFrame\\n    full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\\n\\n    # Save the full merged data to CSV\\n    # Save the full merged data to CSV in the specified folder\\n    full_merged_data1.to_csv(f\\'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv\\', index=False)\\n    print(f\"Batch {i} completed.\")'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import json\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "Batch_size = 50\n",
        "full_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\n",
        "\n",
        "for i in range(3450, len(data), Batch_size):\n",
        "    batch = data[i:i+Batch_size]\n",
        "    dct1 = batch[['index','Headline']].to_dict(orient='records')\n",
        "    json_string1 = json.dumps(dct1)\n",
        "\n",
        "    chat_session = model.start_chat(\n",
        "        history=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    json_string1\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "    print(\"Sleeping\")\n",
        "    time.sleep(10)  # Wait for 30 second between requests\n",
        "    print(\"Woke UP\")\n",
        "    # Clean the data by stripping the backticks and any unwanted characters\n",
        "    json_data1 = response1.text.strip(\"`\").strip(\"json\")\n",
        "\n",
        "    # Load the cleaned data and convert to DataFrame\n",
        "    jsontolist1 = json.loads(json_data1)\n",
        "    df_sample1 = pd.DataFrame(jsontolist1)\n",
        "\n",
        "    # Merge the dataframes\n",
        "    merged_data1 = pd.merge(data, df_sample1, on='index')\n",
        "\n",
        "    # Update the full merged data DataFrame\n",
        "    full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\n",
        "\n",
        "    # Save the full merged data to CSV\n",
        "    # Save the full merged data to CSV in the specified folder\n",
        "    full_merged_data1.to_csv(f'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv', index=False)\n",
        "    print(f\"Batch {i} completed.\")'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "Batch_size = 50\n",
        "full_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\n",
        "z=3850\n",
        "for i in range(z, len(data), Batch_size):\n",
        "    batch = data[i:i+Batch_size]\n",
        "    dct1 = batch[['index', 'Headline']].to_dict(orient='records')\n",
        "    json_string1 = json.dumps(dct1)\n",
        "\n",
        "    chat_session = model.start_chat(\n",
        "        history=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    json_string1\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "        print(\"Sleeping\")\n",
        "        time.sleep(10)  # Wait for 30 seconds between requests\n",
        "        print(\"Woke UP\")\n",
        "        # Clean the data by stripping the backticks and any unwanted characters\n",
        "        json_data1 = response1.text.strip(\"`\").strip(\"json\")\n",
        "\n",
        "        # Load the cleaned data and convert to DataFrame\n",
        "        jsontolist1 = json.loads(json_data1)\n",
        "        df_sample1 = pd.DataFrame(jsontolist1)\n",
        "\n",
        "        # Merge the dataframes\n",
        "        merged_data1 = pd.merge(data, df_sample1, on='index')\n",
        "\n",
        "        # Update the full merged data DataFrame\n",
        "        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\n",
        "\n",
        "        # Save the full merged data to CSV\n",
        "        full_merged_data1.to_csv(f'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv', index=False)\n",
        "        print(f\"Batch {i} completed.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\n",
        "        # Refresh dct1 to a fresh batch\n",
        "        dct1 = []\n",
        "        z=i\n",
        "        continue\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sleeping\n",
        "Woke UP\n",
        "Batch 3850 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 3900 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 3950 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4000 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4050 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4100 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4150 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4200 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4250 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4300 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4350 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4400 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4450 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4500 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4550 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4600 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4650 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4700 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4750 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4800 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4850 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4900 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 4950 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5000 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5050 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5100 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5150 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5200 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5250 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5300 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5350 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "JSONDecodeError: Extra data: line 3 column 1 (char 1816). Refreshing dct1 to a fresh batch.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5450 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5500 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5550 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5600 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5650 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5700 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5750 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5800 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5850 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5900 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 5950 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6000 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6050 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6100 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6150 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6200 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6250 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6300 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6350 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "JSONDecodeError: Extra data: line 3 column 1 (char 1825). Refreshing dct1 to a fresh batch.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6450 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6500 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6550 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6600 completed.\n",
        "Sleeping\n",
        "Woke UP\n",
        "Batch 6650 completed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import json\\nimport pandas as pd\\nimport time\\n\\nBatch_size = 50\\nfull_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\\nz=7450\\nfor i in range(z, len(data), Batch_size):\\n    batch = data[i:i+Batch_size]\\n    dct1 = batch[[\\'index\\', \\'Headline\\']].to_dict(orient=\\'records\\')\\n    json_string1 = json.dumps(dct1)\\n\\n    chat_session = model.start_chat(\\n        history=[\\n            {\\n                \"role\": \"user\",\\n                \"parts\": [\\n                    json_string1\\n                ],\\n            },\\n        ]\\n    )\\n\\n    try:\\n        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\\n        print(\"Sleeping\")\\n        time.sleep(10)  # Wait for 30 seconds between requests\\n        print(\"Woke UP\")\\n        # Clean the data by stripping the backticks and any unwanted characters\\n        json_data1 = response1.text.strip(\"`\").strip(\"json\")\\n\\n        # Load the cleaned data and convert to DataFrame\\n        jsontolist1 = json.loads(json_data1)\\n        df_sample1 = pd.DataFrame(jsontolist1)\\n\\n        # Merge the dataframes\\n        merged_data1 = pd.merge(data, df_sample1, on=\\'index\\')\\n\\n        # Update the full merged data DataFrame\\n        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\\n\\n        # Save the full merged data to CSV\\n        full_merged_data1.to_csv(f\\'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv\\', index=False)\\n        print(f\"Batch {i} completed.\")\\n    except json.JSONDecodeError as e:\\n        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\\n        # Refresh dct1 to a fresh batch\\n        dct1 = []\\n        z=i-50\\n        #Should Have added i=i-50 also\\n        continue\\n\\n    \\n'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import json\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "Batch_size = 50\n",
        "full_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\n",
        "z=7450\n",
        "for i in range(z, len(data), Batch_size):\n",
        "    batch = data[i:i+Batch_size]\n",
        "    dct1 = batch[['index', 'Headline']].to_dict(orient='records')\n",
        "    json_string1 = json.dumps(dct1)\n",
        "\n",
        "    chat_session = model.start_chat(\n",
        "        history=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    json_string1\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "        print(\"Sleeping\")\n",
        "        time.sleep(10)  # Wait for 30 seconds between requests\n",
        "        print(\"Woke UP\")\n",
        "        # Clean the data by stripping the backticks and any unwanted characters\n",
        "        json_data1 = response1.text.strip(\"`\").strip(\"json\")\n",
        "\n",
        "        # Load the cleaned data and convert to DataFrame\n",
        "        jsontolist1 = json.loads(json_data1)\n",
        "        df_sample1 = pd.DataFrame(jsontolist1)\n",
        "\n",
        "        # Merge the dataframes\n",
        "        merged_data1 = pd.merge(data, df_sample1, on='index')\n",
        "\n",
        "        # Update the full merged data DataFrame\n",
        "        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\n",
        "\n",
        "        # Save the full merged data to CSV\n",
        "        full_merged_data1.to_csv(f'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv', index=False)\n",
        "        print(f\"Batch {i} completed.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\n",
        "        # Refresh dct1 to a fresh batch\n",
        "        dct1 = []\n",
        "        z=i-50\n",
        "        #Should Have added i=i-50 also\n",
        "        continue\n",
        "\n",
        "    \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import json\\nimport pandas as pd\\nimport time\\n\\nBatch_size = 50\\nfull_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\\nz=7450\\nfor i in range(z, len(data), Batch_size):\\n    batch = data[i:i+Batch_size]\\n    dct1 = batch[[\\'index\\', \\'Headline\\']].to_dict(orient=\\'records\\')\\n    json_string1 = json.dumps(dct1)\\n\\n    chat_session = model.start_chat(\\n        history=[\\n            {\\n                \"role\": \"user\",\\n                \"parts\": [\\n                    json_string1\\n                ],\\n            },\\n        ]\\n    )\\n\\n    try:\\n        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\\n        print(\"Sleeping\")\\n        time.sleep(10)  # Wait for 30 seconds between requests\\n        print(\"Woke UP\")\\n        # Clean the data by stripping the backticks and any unwanted characters\\n        json_data1 = response1.text.strip(\"`\").strip(\"json\")\\n\\n        # Load the cleaned data and convert to DataFrame\\n        jsontolist1 = json.loads(json_data1)\\n        df_sample1 = pd.DataFrame(jsontolist1)\\n\\n        # Merge the dataframes\\n        merged_data1 = pd.merge(data, df_sample1, on=\\'index\\')\\n\\n        # Update the full merged data DataFrame\\n        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\\n\\n        # Save the full merged data to CSV\\n        full_merged_data1.to_csv(f\\'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv\\', index=False)\\n        print(f\"Batch {i} completed.\")\\n    except json.JSONDecodeError as e:\\n        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\\n        # Refresh dct1 to a fresh batch\\n        dct1 = []\\n        z=i-50\\n        #Should Have added i=i-50 also\\n        continue\\n\\n    \\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import json\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "Batch_size = 50\n",
        "full_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\n",
        "z=7450\n",
        "for i in range(z, len(data), Batch_size):\n",
        "    batch = data[i:i+Batch_size]\n",
        "    dct1 = batch[['index', 'Headline']].to_dict(orient='records')\n",
        "    json_string1 = json.dumps(dct1)\n",
        "\n",
        "    chat_session = model.start_chat(\n",
        "        history=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    json_string1\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "        print(\"Sleeping\")\n",
        "        time.sleep(10)  # Wait for 30 seconds between requests\n",
        "        print(\"Woke UP\")\n",
        "        # Clean the data by stripping the backticks and any unwanted characters\n",
        "        json_data1 = response1.text.strip(\"`\").strip(\"json\")\n",
        "\n",
        "        # Load the cleaned data and convert to DataFrame\n",
        "        jsontolist1 = json.loads(json_data1)\n",
        "        df_sample1 = pd.DataFrame(jsontolist1)\n",
        "\n",
        "        # Merge the dataframes\n",
        "        merged_data1 = pd.merge(data, df_sample1, on='index')\n",
        "\n",
        "        # Update the full merged data DataFrame\n",
        "        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\n",
        "\n",
        "        # Save the full merged data to CSV\n",
        "        full_merged_data1.to_csv(f'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/SENT_ANAL/merged_data_till.{i}.csv', index=False)\n",
        "        print(f\"Batch {i} completed.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\n",
        "        # Refresh dct1 to a fresh batch\n",
        "        dct1 = []\n",
        "        z=i-50\n",
        "        #Should Have added i=i-50 also\n",
        "        continue\n",
        "\n",
        "    \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import os\\nimport google.generativeai as genai\\ngenai.configure(api_key=\"AIzaSyA9-COrUP5zX1frzRAxls1lhJJ8Cw7F1AQ\")\\n\\nimport json\\nimport pandas as pd\\nimport time\\n# Create the model\\n# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\\ngeneration_config = {\\n  \"temperature\": 0,\\n  \"top_p\": 0.95,\\n  \"top_k\": 64,\\n  \"max_output_tokens\":100000 ,\\n  \"response_mime_type\": \"text/plain\",\\n}\\nsafety_settings = [\\n  {\\n    \"category\": \"HARM_CATEGORY_HARASSMENT\",\\n    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\\n  },\\n  {\\n    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\\n    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\\n  },\\n  {\\n    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\\n    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\\n  },\\n  {\\n    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\\n    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\\n  },\\n]\\n\\nmodel = genai.GenerativeModel(\\n  model_name=\"gemini-1.5-pro-latest\",\\n  safety_settings=safety_settings,\\n  generation_config=generation_config,\\n  system_instruction=\"You are an advanced sentiment analysis model designed to evaluate the sentiment of news headlines related to cryptocurrency. Your task is to categorize each headline into one of three categories: positive, negative, or neutral. \\n A positive sentiment indicates that the headline is likely to have a beneficial impact on the perception of the cryptocurrency market, suggesting optimism or good news.\\nA negative sentiment indicates that the headline is likely to have an adverse impact on the perception of the cryptocurrency market, suggesting pessimism or bad news.\\nA neutral sentiment indicates that the headline does not express a clear positive or negative sentiment, or it has no significant impact on the perception of the cryptocurrency market.\\nFor each headline, provide a sentiment score ranging from -1 to 1, where:\\n- A score close to 1 indicates a strong positive sentiment,\\n- A score close to -1 indicates a strong negative sentiment,\\n- A score close to 0 indicates a neutral sentiment.\\n\\nHere are some examples for clarity:\\n1. Headline: \"Bitcoin prices soar to new all-time high.\"\\n   Sentiment: Positive\\n   Score: 0.9\\n2. Headline: \"Cryptocurrency market faces regulatory crackdowns.\"\\n   Sentiment: Negative\\n   Score: -0.8\\n3. Headline: \"Blockchain technology adoption continues to grow steadily.\"\\n   Sentiment: Neutral\\n   Score: 0.1\\nYour task is to update predicted score under \\'pred_label\\' in the json provided. Don\\'t make any changes to the Output format..\\nPlease analyze the following headlines and provide the sentiment and score for each:\\nNote: The analysis should be consistent across repeated evaluations of the same headlines.Note: Output should only have Index and corresponding pred_score \",)\\n\\nsam=[11450,15550,19700,21850,24900,24900,26200]\\nBatch_size = 50\\nfull_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\\n\\nfor i in sam:\\n    batch = data[i:i+Batch_size]\\n    dct1 = batch[[\\'index\\', \\'Headline\\']].to_dict(orient=\\'records\\')\\n    json_string1 = json.dumps(dct1)\\n\\n    chat_session = model.start_chat(\\n        history=[\\n            {\\n                \"role\": \"user\",\\n                \"parts\": [\\n                    json_string1\\n                ],\\n            },\\n        ]\\n    )\\n    try:\\n        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\\n        print(\"Sleeping\")\\n        time.sleep(10)  # Wait for 30 seconds between requests\\n        print(\"Woke UP\")\\n        # Clean the data by stripping the backticks and any unwanted characters\\n        json_data1 = response1.text.strip(\"`\").strip(\"json\")\\n\\n        # Load the cleaned data and convert to DataFrame\\n        jsontolist1 = json.loads(json_data1)\\n        df_sample1 = pd.DataFrame(jsontolist1)\\n\\n        # Merge the dataframes\\n        merged_data1 = pd.merge(data, df_sample1, on=\\'index\\')\\n\\n        # Update the full merged data DataFrame\\n        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\\n\\n        # Save the full merged data to CSV\\n        full_merged_data1.to_csv(f\\'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/test/merged_data_till.{i}.csv\\', index=False)\\n        print(f\"Batch {i} completed.\")\\n    except json.JSONDecodeError as e:\\n        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\\n        # Refresh dct1 to a fresh batch\\n        dct1 = []\\n        i=i-1\\n        #Should Have added i=i-50 also\\n        continue\\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import os\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyA9-COrUP5zX1frzRAxls1lhJJ8Cw7F1AQ\")\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "# Create the model\n",
        "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
        "generation_config = {\n",
        "  \"temperature\": 0,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\":100000 ,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-pro-latest\",\n",
        "  safety_settings=safety_settings,\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"You are an advanced sentiment analysis model designed to evaluate the sentiment of news headlines related to cryptocurrency. Your task is to categorize each headline into one of three categories: positive, negative, or neutral. \\n A positive sentiment indicates that the headline is likely to have a beneficial impact on the perception of the cryptocurrency market, suggesting optimism or good news.\\nA negative sentiment indicates that the headline is likely to have an adverse impact on the perception of the cryptocurrency market, suggesting pessimism or bad news.\\nA neutral sentiment indicates that the headline does not express a clear positive or negative sentiment, or it has no significant impact on the perception of the cryptocurrency market.\\nFor each headline, provide a sentiment score ranging from -1 to 1, where:\\n- A score close to 1 indicates a strong positive sentiment,\\n- A score close to -1 indicates a strong negative sentiment,\\n- A score close to 0 indicates a neutral sentiment.\\n\\nHere are some examples for clarity:\\n1. Headline: \\\"Bitcoin prices soar to new all-time high.\\\"\\n   Sentiment: Positive\\n   Score: 0.9\\n2. Headline: \\\"Cryptocurrency market faces regulatory crackdowns.\\\"\\n   Sentiment: Negative\\n   Score: -0.8\\n3. Headline: \\\"Blockchain technology adoption continues to grow steadily.\\\"\\n   Sentiment: Neutral\\n   Score: 0.1\\nYour task is to update predicted score under 'pred_label' in the json provided. Don't make any changes to the Output format..\\nPlease analyze the following headlines and provide the sentiment and score for each:\\nNote: The analysis should be consistent across repeated evaluations of the same headlines.Note: Output should only have Index and corresponding pred_score \",)\n",
        "\n",
        "sam=[11450,15550,19700,21850,24900,24900,26200]\n",
        "Batch_size = 50\n",
        "full_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\n",
        "\n",
        "for i in sam:\n",
        "    batch = data[i:i+Batch_size]\n",
        "    dct1 = batch[['index', 'Headline']].to_dict(orient='records')\n",
        "    json_string1 = json.dumps(dct1)\n",
        "\n",
        "    chat_session = model.start_chat(\n",
        "        history=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    json_string1\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "    try:\n",
        "        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "        print(\"Sleeping\")\n",
        "        time.sleep(10)  # Wait for 30 seconds between requests\n",
        "        print(\"Woke UP\")\n",
        "        # Clean the data by stripping the backticks and any unwanted characters\n",
        "        json_data1 = response1.text.strip(\"`\").strip(\"json\")\n",
        "\n",
        "        # Load the cleaned data and convert to DataFrame\n",
        "        jsontolist1 = json.loads(json_data1)\n",
        "        df_sample1 = pd.DataFrame(jsontolist1)\n",
        "\n",
        "        # Merge the dataframes\n",
        "        merged_data1 = pd.merge(data, df_sample1, on='index')\n",
        "\n",
        "        # Update the full merged data DataFrame\n",
        "        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\n",
        "\n",
        "        # Save the full merged data to CSV\n",
        "        full_merged_data1.to_csv(f'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/test/merged_data_till.{i}.csv', index=False)\n",
        "        print(f\"Batch {i} completed.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\n",
        "        # Refresh dct1 to a fresh batch\n",
        "        dct1 = []\n",
        "        i=i-1\n",
        "        #Should Have added i=i-50 also\n",
        "        continue\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sleeping\n",
            "Woke UP\n",
            "Batch 7550 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 9350 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 9950 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 10250 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "JSONDecodeError: Extra data: line 3 column 1 (char 6573). Refreshing dct1 to a fresh batch.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 11150 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 12000 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 12150 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 12450 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 12600 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 12650 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 12800 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 13150 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 13250 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 13500 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 13650 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 13700 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 14600 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 15650 completed.\n",
            "Sleeping\n",
            "Woke UP\n",
            "Batch 16050 completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyA9-COrUP5zX1frzRAxls1lhJJ8Cw7F1AQ\")\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "# Create the model\n",
        "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
        "generation_config = {\n",
        "  \"temperature\": 0,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\":100000 ,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "  },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-pro-latest\",\n",
        "  safety_settings=safety_settings,\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"You are an advanced sentiment analysis model designed to evaluate the sentiment of news headlines related to cryptocurrency. Your task is to categorize each headline into one of three categories: positive, negative, or neutral. \\n A positive sentiment indicates that the headline is likely to have a beneficial impact on the perception of the cryptocurrency market, suggesting optimism or good news.\\nA negative sentiment indicates that the headline is likely to have an adverse impact on the perception of the cryptocurrency market, suggesting pessimism or bad news.\\nA neutral sentiment indicates that the headline does not express a clear positive or negative sentiment, or it has no significant impact on the perception of the cryptocurrency market.\\nFor each headline, provide a sentiment score ranging from -1 to 1, where:\\n- A score close to 1 indicates a strong positive sentiment,\\n- A score close to -1 indicates a strong negative sentiment,\\n- A score close to 0 indicates a neutral sentiment.\\n\\nHere are some examples for clarity:\\n1. Headline: \\\"Bitcoin prices soar to new all-time high.\\\"\\n   Sentiment: Positive\\n   Score: 0.9\\n2. Headline: \\\"Cryptocurrency market faces regulatory crackdowns.\\\"\\n   Sentiment: Negative\\n   Score: -0.8\\n3. Headline: \\\"Blockchain technology adoption continues to grow steadily.\\\"\\n   Sentiment: Neutral\\n   Score: 0.1\\nYour task is to update predicted score under 'pred_label' in the json provided. Don't make any changes to the Output format..\\nPlease analyze the following headlines and provide the sentiment and score for each:\\nNote: The analysis should be consistent across repeated evaluations of the same headlines.Note: Output should only have Index and corresponding pred_score \",)\n",
        "\n",
        "\n",
        "Batch_size = 50\n",
        "full_merged_data1 = pd.DataFrame()  # Initialize the DataFrame before the loop\n",
        "list1=[7550,9350,9950,10250,10600,11150,12000,12150,12450,12600,12650,12800,13150,13250,13500,13650,13700,14600,15650,16050]\n",
        "for i in list1:\n",
        "    batch = data[i:i+Batch_size]\n",
        "    dct1 = batch[['index', 'Headline']].to_dict(orient='records')\n",
        "    json_string1 = json.dumps(dct1)\n",
        "\n",
        "    chat_session = model.start_chat(\n",
        "        history=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    json_string1\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "    )\n",
        "    try:\n",
        "        response1 = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "        print(\"Sleeping\")\n",
        "        time.sleep(10)  # Wait for 30 seconds between requests\n",
        "        print(\"Woke UP\")\n",
        "        # Clean the data by stripping the backticks and any unwanted characters\n",
        "        json_data1 = response1.text.strip(\"`\").strip(\"json\")\n",
        "\n",
        "        # Load the cleaned data and convert to DataFrame\n",
        "        jsontolist1 = json.loads(json_data1)\n",
        "        df_sample1 = pd.DataFrame(jsontolist1)\n",
        "\n",
        "        # Merge the dataframes\n",
        "        merged_data1 = pd.merge(data, df_sample1, on='index')\n",
        "\n",
        "        # Update the full merged data DataFrame\n",
        "        full_merged_data1 = pd.concat([full_merged_data1, merged_data1], ignore_index=True)\n",
        "\n",
        "        # Save the full merged data to CSV\n",
        "        full_merged_data1.to_csv(f'D:/DATA SCIENCE/Internship/CrypoDataAnalysis/test/merged_data_till.{i}.csv', index=False)\n",
        "        print(f\"Batch {i} completed.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSONDecodeError: {e}. Refreshing dct1 to a fresh batch.\")\n",
        "        # Refresh dct1 to a fresh batch\n",
        "        dct1 = []\n",
        "        i=i-1\n",
        "        #Should Have added i=i-50 also\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JCqrJeft-MQ"
      },
      "source": [
        "# **ROUGH_WORK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iz7JuUj5PKxy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"# Convert the DataFrame to JSON using the to_json() method\\n\\njson_data = test_set_sample[['clean_headlines','pred_label']].to_json(orient='records')\\n\\n# Print the JSON data\\nprint(json_data)\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''# Convert the DataFrame to JSON using the to_json() method\n",
        "\n",
        "json_data = test_set_sample[['clean_headlines','pred_label']].to_json(orient='records')\n",
        "\n",
        "# Print the JSON data\n",
        "print(json_data)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "poATCYg5kaEQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
            "C:\\Users\\Nahala\\AppData\\Local\\Temp\\ipykernel_20468\\2979411504.py:1: SyntaxWarning: invalid escape sequence '\\w'\n",
            "  '''import re\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'import re\\n\\ndef clean_text(text):\\n  # Remove special characters and punctuation\\n  text = re.sub(r\"[^\\\\w\\\\s]\", \" \", text)\\n\\n  # Remove single characters\\n  text = re.sub(r\"\\x08[a-zA-Z]\\x08\", \" \", text)\\n\\n  # Remove HTML tags\\n  text = re.sub(r\"<[^>]*>\", \" \", text)\\n\\n  # Lowercase the text\\n  text = text.lower()\\n\\n  # Remove extra whitespace\\n  text = re.sub(r\"\\\\s+\", \" \", text)\\n\\n  # Trim leading and trailing spaces\\n  text = text.strip()\\n\\n  return text'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import re\n",
        "\n",
        "def clean_text(text):\n",
        "  # Remove special characters and punctuation\n",
        "  text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
        "\n",
        "  # Remove single characters\n",
        "  text = re.sub(r\"\\b[a-zA-Z]\\b\", \" \", text)\n",
        "\n",
        "  # Remove HTML tags\n",
        "  text = re.sub(r\"<[^>]*>\", \" \", text)\n",
        "\n",
        "  # Lowercase the text\n",
        "  text = text.lower()\n",
        "\n",
        "  # Remove extra whitespace\n",
        "  text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "  # Trim leading and trailing spaces\n",
        "  text = text.strip()\n",
        "\n",
        "  return text'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rBniJ41CK5j9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"import pandas as pd\\n\\n# Extract the review column as a list\\nheadlines = data['Headline'].tolist()\\n\\n# Clean the text in the list\\ncleaned_headlines = [clean_text(headline) for headline in headlines]\\n\\n# Add the cleaned reviews as a new column to the DataFrame\\ndata['clean_headlines'] = cleaned_headlines\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import pandas as pd\n",
        "\n",
        "# Extract the review column as a list\n",
        "headlines = data['Headline'].tolist()\n",
        "\n",
        "# Clean the text in the list\n",
        "cleaned_headlines = [clean_text(headline) for headline in headlines]\n",
        "\n",
        "# Add the cleaned reviews as a new column to the DataFrame\n",
        "data['clean_headlines'] = cleaned_headlines'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nCCaLkf8lGgQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"clean_data=data[['Date','clean_headlines']]\\nclean_data['pred_label']=''\\nclean_data.set_index('Date',inplace=True)\\nclean_data\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''clean_data=data[['Date','clean_headlines']]\n",
        "clean_data['pred_label']=''\n",
        "clean_data.set_index('Date',inplace=True)\n",
        "clean_data'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NAQg7wnnX-ia"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[{\"index\": 1, \"pred_score\": 0.3}, {\"index\": 2, \"pred_score\": 0.1}, {\"index\": 3, \"pred_score\": 0.2}, {\"index\": 4, \"pred_score\": 0.0}, {\"index\": 5, \"pred_score\": 0.4}, {\"index\": 6, \"pred_score\": -0.1}, {\"index\": 7, \"pred_score\": 0.0}, {\"index\": 8, \"pred_score\": 0.7}, {\"index\": 9, \"pred_score\": 0.3}, {\"index\": 10, \"pred_score\": 0.1}]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nESB5qGTDogH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt Token Count: 633\n"
          ]
        }
      ],
      "source": [
        "# Prompt tokens count\n",
        "input = model.count_tokens(json_string)\n",
        "print(f\"Prompt Token Count: {input.total_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J3LZdXrcXWDO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "344"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "j6MYEj5FEWaT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output Token Count: 522\n"
          ]
        }
      ],
      "source": [
        "# Prompt tokens count\n",
        "output = model.count_tokens(response.text)\n",
        "print(f\"output Token Count: {output.total_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1Po4hu1QEk2-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# Prompt tokens count\\nresponse = model.count_tokens(prompt)\\nprint(f\"Prompt Token Count: {response.total_tokens}\")\\nprint(f\"Prompt Character Count: {response.total_billable_characters}\")\\n\\n# Send text to Gemini\\nresponse = model.generate_content(prompt)\\n\\n# Response tokens count\\nusage_metadata = response.usage_metadata\\nprint(f\"Prompt Token Count: {usage_metadata.prompt_token_count}\")\\nprint(f\"Candidates Token Count: {usage_metadata.candidates_token_count}\")\\nprint(f\"Total Token Count: {usage_metadata.total_token_count}\")'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''# Prompt tokens count\n",
        "response = model.count_tokens(prompt)\n",
        "print(f\"Prompt Token Count: {response.total_tokens}\")\n",
        "print(f\"Prompt Character Count: {response.total_billable_characters}\")\n",
        "\n",
        "# Send text to Gemini\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# Response tokens count\n",
        "usage_metadata = response.usage_metadata\n",
        "print(f\"Prompt Token Count: {usage_metadata.prompt_token_count}\")\n",
        "print(f\"Candidates Token Count: {usage_metadata.candidates_token_count}\")\n",
        "print(f\"Total Token Count: {usage_metadata.total_token_count}\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tXsem4xa8jY5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "344"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qM0fbkPSrzs3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Date</th>\n",
              "      <th>pred_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>UAE Pro League Teams Up With Chiliz to Bring W...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Polkadot Price Forecast: Will DOT Reach the $5...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Binance Opts for USDC Reserves While It Seeks ...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Worldcoin Introduces World Chain Layer-2 Amids...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>BlackRock Was Tipped Off About High Inflation,...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Is the Bitcoin, Crypto Bull Market Over? Analy...</td>\n",
              "      <td>18-Apr-24</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Ripple (XRP) Price Analysis: 13% Recovery or 1...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>This Is How Nearly 1 Billion Polygon (MATIC) W...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Shiba Inu (SHIB) Price Forecast: Potential Bul...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Will Pepe (PEPE) Price Mark a New All-Time Hig...</td>\n",
              "      <td>17-Apr-24</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                           Headline       Date  \\\n",
              "0      1  UAE Pro League Teams Up With Chiliz to Bring W...  18-Apr-24   \n",
              "1      2  Polkadot Price Forecast: Will DOT Reach the $5...  18-Apr-24   \n",
              "2      3  Binance Opts for USDC Reserves While It Seeks ...  18-Apr-24   \n",
              "3      4  Worldcoin Introduces World Chain Layer-2 Amids...  18-Apr-24   \n",
              "4      5  BlackRock Was Tipped Off About High Inflation,...  18-Apr-24   \n",
              "5      6  Is the Bitcoin, Crypto Bull Market Over? Analy...  18-Apr-24   \n",
              "6      7  Ripple (XRP) Price Analysis: 13% Recovery or 1...  17-Apr-24   \n",
              "7      8  This Is How Nearly 1 Billion Polygon (MATIC) W...  17-Apr-24   \n",
              "8      9  Shiba Inu (SHIB) Price Forecast: Potential Bul...  17-Apr-24   \n",
              "9     10  Will Pepe (PEPE) Price Mark a New All-Time Hig...  17-Apr-24   \n",
              "\n",
              "   pred_score  \n",
              "0         0.3  \n",
              "1         0.1  \n",
              "2         0.2  \n",
              "3         0.0  \n",
              "4         0.4  \n",
              "5        -0.1  \n",
              "6         0.0  \n",
              "7         0.7  \n",
              "8         0.3  \n",
              "9         0.1  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_data = pd.merge(test_set_sample, df_sample, on='index')\n",
        "merged_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
